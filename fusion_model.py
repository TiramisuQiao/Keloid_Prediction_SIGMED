import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import numpy as np
import pickle
import os
from torchvision import transforms
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ViT æ¨¡å‹å®šä¹‰ (vit.py)
class Swish(nn.Module):
    def forward(self, x):
        return x * torch.sigmoid(x)

from vit import ViT

# MLP å…ƒæ•°æ®æ¨¡å‹å®šä¹‰
class MetadataMLP_PL(torch.nn.Module):
    def __init__(self, input_dim=27, hidden_dim=64, output_dim=2, dropout_p=0.1):
        super().__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            Swish(),
            nn.Dropout(p=dropout_p),
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            Swish(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            Swish()
        )
        self.output_layer = nn.Linear(hidden_dim, output_dim)
    
    def forward(self, x):
        x = self.feature_extractor(x)
        return self.output_layer(x)

# è‡ªå®šä¹‰æ•°æ®é›†ç±»
class ImageMetaLabelDataset(Dataset):
    def __init__(self, images_file, meta_file, label_file, image_size=224):
        with open(images_file, 'rb') as f:
            self.images = pickle.load(f)
        with open(meta_file, 'rb') as f:
            self.meta = pickle.load(f)
        with open(label_file, 'rb') as f:
            self.labels = pickle.load(f)

        assert len(self.images) == len(self.meta) == len(self.labels), "æ•°æ®é•¿åº¦ä¸ä¸€è‡´"

        # å›¾åƒé¢„å¤„ç†ç®¡é“
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
        ])

        # å…ƒæ•°æ®è½¬tensor
        self.meta = torch.tensor(np.array(self.meta), dtype=torch.float32)
        self.labels = torch.tensor(np.array(self.labels), dtype=torch.long)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        # å›¾åƒå¤„ç†
        image = self.images[idx]
        if not isinstance(image, np.ndarray):
            image = np.array(image)
        
        # å¤„ç†å›¾åƒç»´åº¦
        if image.ndim == 1:
            image = image.reshape(224, 224, 3)
        elif image.shape[0] == 3 and image.ndim == 3:
            image = np.transpose(image, (1, 2, 0))
        
        image = self.transform(image)
        return image, self.meta[idx], self.labels[idx]

# æ¨¡å‹åŠ è½½å‡½æ•°
def load_vit_model(checkpoint_path, device='cuda'):
    """åŠ è½½ViTå›¾åƒæ¨¡å‹"""
    config = {
        'image_size': 224,
        'patch_size': 16,
        'num_classes': 2,
        'dim': 768,
        'depth': 12,
        'heads': 12,
        'mlp_dim': 3072,
        'channels': 3,
        'dropout': 0.1,
        'emb_dropout': 0.1
    }
    
    vit = ViT(**config).to(device)
    ckpt = torch.load(checkpoint_path, map_location=device)
    state_dict = ckpt.get('state_dict', ckpt)
    
    new_state_dict = {}
    for k, v in state_dict.items():
        name = k.replace('model.', '').replace('net.', '')
        new_state_dict[name] = v
    
    vit.load_state_dict(new_state_dict)
    vit.eval()
    return vit

def load_mlp_model(checkpoint_path, device='cuda'):
    """åŠ è½½MLPå…ƒæ•°æ®æ¨¡å‹"""
    mlp = MetadataMLP_PL().to(device)
    ckpt = torch.load(checkpoint_path, map_location=device)
    state_dict = ckpt.get('state_dict', ckpt)
    
    new_state_dict = {}
    for k, v in state_dict.items():
        name = k.replace('model.', '').replace('net.', '')
        new_state_dict[name] = v
    
    mlp.load_state_dict(new_state_dict)
    mlp.eval()
    return mlp

# è·å–å…¨éƒ¨é¢„æµ‹ç»“æœ
def get_all_predictions(model, dataloader, model_type='vit'):
    """è·å–æ¨¡å‹å¯¹æ•´ä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœ"""
    all_logits = []
    all_labels = []
    
    device = next(model.parameters()).device
    
    with torch.no_grad():
        for batch in dataloader:
            images, metas, labels = batch
            if model_type == 'vit':
                inputs = images.to(device)
            else:
                inputs = metas.to(device)
            
            logits = model(inputs)
            all_logits.append(logits.cpu())
            all_labels.append(labels)
    
    return (
        torch.cat(all_logits),
        torch.cat(all_labels)
    )

# æƒé‡æ‰«æå‡½æ•°
def evaluate_weighted_accuracy(vit_logits, mlp_logits, true_labels):
    """æ‰«æä¸åŒæƒé‡ç»„åˆï¼Œè®¡ç®—èåˆå‡†ç¡®ç‡"""
    results = []
    weights = np.arange(0.0, 1.01, 0.01)  # ä»0åˆ°1ï¼Œæ­¥é•¿0.01
    
    for alpha in weights:
        # åŠ æƒèåˆ (alphaæ§åˆ¶ViTè´¡çŒ®åº¦)
        combined_logits = alpha * vit_logits + (1 - alpha) * mlp_logits
        
        # è®¡ç®—å‡†ç¡®ç‡
        preds = torch.argmax(combined_logits, dim=1)
        accuracy = (preds == true_labels).float().mean().item()
        
        results.append({
            'alpha': round(alpha, 2),
            'accuracy': round(accuracy, 4)
        })
    
    return pd.DataFrame(results)

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # è®¾å¤‡é…ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    os.makedirs('results', exist_ok=True)
    
    # åŠ è½½æ•°æ®é›†
    dataset = ImageMetaLabelDataset(
        images_file="dataset/images.pkl",
        meta_file="dataset/meta.pickle",
        label_file="dataset/labels.pkl"
    )
    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”„ åŠ è½½ViTå›¾åƒæ¨¡å‹...")
    vit = load_vit_model("checkpoints/vit_best.ckpt", device=device)
    
    print("\nğŸ”„ åŠ è½½MLPå…ƒæ•°æ®æ¨¡å‹...")
    mlp = load_mlp_model("checkpoints/mlp_best.ckpt", device=device)
    
    # è·å–æ‰€æœ‰é¢„æµ‹ç»“æœ
    print("\nğŸ” è·å–ViTæ¨¡å‹é¢„æµ‹ç»“æœ...")
    vit_logits, true_labels = get_all_predictions(vit, dataloader, model_type='vit')
    
    print("\nğŸ” è·å–MLPæ¨¡å‹é¢„æµ‹ç»“æœ...")
    mlp_logits, _ = get_all_predictions(mlp, dataloader, model_type='mlp')
    
    # æƒé‡æ‰«æ
    print("\nğŸ” å¼€å§‹æ‰«ææƒé‡ç»„åˆ...")
    results_df = evaluate_weighted_accuracy(vit_logits, mlp_logits, true_labels)
    
    # æ‰¾åˆ°æœ€ä½³æƒé‡
    best_row = results_df.loc[results_df['accuracy'].idxmax()]
    print(f"\nğŸ† æœ€ä½³æƒé‡ç»„åˆ: Î±={best_row['alpha']}, å‡†ç¡®ç‡={best_row['accuracy']:.4f}")
    
    # ä¿å­˜ç»“æœ
    results_df.to_csv("results/weighted_results.csv", index=False)
    
    # å¯è§†åŒ–
    plt.figure(figsize=(12, 6))
    sns.lineplot(data=results_df, x='alpha', y='accuracy')
    plt.title('Ensemble Accuracy vs ViT Weight (Î±)')
    plt.xlabel('ViT Weight (Î±)')
    plt.ylabel('Validation Accuracy')
    plt.grid(True)
    plt.savefig("results/weight_analysis.png")
    plt.show()